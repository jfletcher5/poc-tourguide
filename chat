from langchain_community.chat_models import ChatOpenAI
from models import ChatArgs
from vector_stores.pinecone import build_retriever
from llms.chaopenai import build_llm
from memories.sql_memory import build_memory
from chains.retrieval import StreamingConversationalRetrievalChain

def build_chat(chat_args: ChatArgs):
    retriever = build_retriever(chat_args)
    llm = build_llm(chat_args)
    condense_question_llm=ChatOpenAI(streaming=False)
    memory = build_memory(chat_args)

    return StreamingConversationalRetrievalChain.from_llm(
        llm=llm,
        condense_question_llm=condense_question_llm,
        memory=memory,
        retriever=retriever
    )
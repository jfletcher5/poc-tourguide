{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"!olleH ,boB m'I !iH\", response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 241, 'total_tokens': 252}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-9a053d60-22ac-4c59-8f6a-c97c3318392b-0', usage_metadata={'input_tokens': 241, 'output_tokens': 11, 'total_tokens': 252})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant. you answer every prompt backwards\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | ChatOpenAI()\n",
    "\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    lambda session_id: SQLChatMessageHistory(\n",
    "        session_id=session_id, connection_string=\"sqlite:///sqlite_test.db\"\n",
    "    ),\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "# This is where we configure the session id\n",
    "config = {\"configurable\": {\"session_id\": \"session2\"}}\n",
    "\n",
    "chain_with_history.invoke({\"question\": \"Hi! I'm bob\"}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='We have exchanged six messages so far. How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 179, 'total_tokens': 194}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-921e478f-2594-4e0e-9829-6fa3e17bdf81-0', usage_metadata={'input_tokens': 179, 'output_tokens': 15, 'total_tokens': 194})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_history.invoke({\"question\": \"how many messages have we exchanged\"}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human: Hi! I'm bob\n",
      "ai: Hello Bob! How can I assist you today?\n",
      "human: Whats my name\n",
      "ai: Your name is Bob.\n",
      "human: Whats my name\n",
      "ai: Your name is Bob.\n",
      "human: what model ai are you\n",
      "ai: I am a language model AI designed to assist and provide information to users. How can I help you today?\n",
      "human: who made you\n",
      "ai: I am powered by OpenAI's GPT-3 technology, which was created by OpenAI, an artificial intelligence research lab.\n",
      "human: how many messages have we exchanged\n",
      "ai: We have exchanged five messages so far. How can I assist you further?\n",
      "human: how many messages have we exchanged\n",
      "ai: We have exchanged six messages so far. How can I assist you today?\n",
      "human: how many messages have we exchanged\n",
      "ai: We have exchanged seven messages so far. How can I help you today?\n",
      "human: Hi! I'm bob\n",
      "ai: !olleH ,boB m'I !iH\n",
      "human: how many messages have we exchanged\n",
      "ai: We have exchanged eight messages so far. How can I assist you further?\n",
      "human: how many messages have we exchanged\n",
      "ai: We have exchanged nine messages so far. How can I help you today?\n",
      "human: how many messages have we exchanged\n",
      "ai: We have exchanged ten messages so far. How can I assist you today?\n",
      "human: how many messages have we exchanged\n",
      "ai: We have exchanged eleven messages so far. How can I help you today?\n",
      "human: how many messages have we exchanged\n",
      "ai: We have exchanged twelve messages so far. How can I assist you further?\n",
      "human: how many messages have we exchanged\n",
      "ai: We have exchanged thirteen messages so far. How can I help you today?\n",
      "human: how many messages have we exchanged\n",
      "ai: We have exchanged fourteen messages so far. How can I assist you further?\n"
     ]
    }
   ],
   "source": [
    "chain_with_history.invoke({\"question\": \"how many messages have we exchanged\"}, config=config)\n",
    "\n",
    "msg = SQLChatMessageHistory(session_id=\"session2\", connection_string=\"sqlite:///sqlite_test.db\")\n",
    "\n",
    "# print(msg.messages)\n",
    "\n",
    "for m in msg.messages:\n",
    "    print(m.type+\": \"+m.content)\n",
    "    # print(m.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
